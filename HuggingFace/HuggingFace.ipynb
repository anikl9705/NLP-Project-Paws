{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7a_-c5fvbWa",
        "colab_type": "code",
        "outputId": "fb0bf612-3af6-4cf8-c0ac-dc6e21d390ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.23)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.23 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.23)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3MLqgPywahc",
        "colab_type": "code",
        "outputId": "c0658b13-3daf-423a-830f-2f2a8e706a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxHwnOz-wElJ",
        "colab_type": "code",
        "outputId": "8ec77dd9-3bb6-4bbc-cc1a-0eb76ef372da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import torch\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "import scipy as scipy\n",
        "import pandas as pd\n",
        "import os\n",
        "import ast\n",
        "import tqdm as tqdm\n",
        "\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdJNWG3X01oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASS, TOKENIZER_CLASS, PRETRAINED = (DistilBertForSequenceClassification, DistilBertTokenizer, 'distilbert-base-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BPg3_DtVIYJ",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocess Data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9WZx3Jwwjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab/data_qqp/'\n",
        "\n",
        "train_data = pd.read_table(os.path.expanduser(data_path+'train.tsv'),header=0)\n",
        "test_data = pd.read_table(os.path.expanduser(data_path+'dev_and_test.tsv'),header=0)\n",
        "\n",
        "train_data['sentence1'] = train_data['sentence1'].apply(lambda x: ast.literal_eval(x).decode())\n",
        "train_data['sentence2'] = train_data['sentence2'].apply(lambda x: ast.literal_eval(x).decode())\n",
        "\n",
        "test_data['sentence1'] = test_data['sentence1'].apply(lambda x: ast.literal_eval(x).decode())\n",
        "test_data['sentence2'] = test_data['sentence2'].apply(lambda x: ast.literal_eval(x).decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXB1JZKf0o37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI0CzB3p0uT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tokenizer:\n",
        "    # init\n",
        "    def __init__(self, tokenizer_class, pretrained_weights, group_sent=False):\n",
        "        self.tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "        self.group_sent = group_sent\n",
        "        \n",
        "    # tokenize\n",
        "    def tokenize_data(self, data):\n",
        "        tokenized = pd.DataFrame(columns = ['i1', 's1', 'i2', 's2', 'i', 's', 'y'])\n",
        "        for index, row in data.iterrows():\n",
        "            token_row = {\n",
        "                'i1' : [],\n",
        "                's1' : [],\n",
        "                'i2' : [],\n",
        "                's2' : [],\n",
        "                'i' : [],\n",
        "                's' : [],\n",
        "                'y': 0\n",
        "            }\n",
        "            sent1 = row['sentence1']\n",
        "            encoding1 = self.tokenizer.encode_plus(sent1, return_token_type_ids=True, max_length=128, pad_to_max_length=True)\n",
        "\n",
        "            token_row['i1'] = encoding1['input_ids']\n",
        "            token_row['s1'] = encoding1['token_type_ids']\n",
        "\n",
        "            # indexed1 = self.tokenizer.encode(sent1, max_length=128, pad_to_max_length=True)\n",
        "            # print(token)\n",
        "            # indexed1 = self.tokenizer.convert_tokens_to_ids(token)\n",
        "            # indexed_tensor = torch.tensor([indexed1])\n",
        "            # segment = np.zeros(len(indexed1), dtype=int)\n",
        "            # segment_tensor = torch.tensor([segment])\n",
        "            # token_row['s1'] = segment_tensor\n",
        "\n",
        "            sent2 = row['sentence2']\n",
        "            encoding2 = self.tokenizer.encode_plus(sent2, return_token_type_ids=True, max_length=128, pad_to_max_length=True)\n",
        "\n",
        "            token_row['i2'] = encoding2['input_ids']\n",
        "            token_row['s2'] = encoding2['token_type_ids']\n",
        "            # indexed2 = self.tokenizer.encode(sent2, max_length=128, pad_to_max_length=True)\n",
        "            # # indexed2 = self.tokenizer.convert_tokens_to_ids(token)\n",
        "            # indexed_tensor = torch.tensor([indexed2])\n",
        "            # token_row['i2'] = indexed_tensor\n",
        "            # segment = np.zeros(len(indexed2), dtype=int)\n",
        "            # segment_tensor = torch.tensor([segment])\n",
        "            # token_row['s2'] = segment_tensor\n",
        "            \n",
        "            if self.group_sent == True:\n",
        "                encoding = self.tokenizer.encode_plus(sent1, sent2, return_token_type_ids=True, max_length=256, pad_to_max_length=True)\n",
        "\n",
        "                token_row['i'] = encoding2['input_ids']\n",
        "                token_row['s'] = encoding2['token_type_ids']\n",
        "\n",
        "                # print(encoding)\n",
        "                # indexed = self.tokenizer.build_inputs_with_special_tokens(indexed1, indexed2)\n",
        "                # token_row['i'] = torch.tensor([indexed])\n",
        "                # # print(torch.tensor([indexed]).shape)\n",
        "\n",
        "                # max_length = max(len(indexed), max_length)\n",
        "\n",
        "                # if len(indexed) > 500:\n",
        "                #     print(sent1 + sent2)\n",
        "                # segment = self.tokenizer.create_token_type_ids_from_sequences(indexed1, indexed2)\n",
        "                # token_row['s'] = torch.tensor([segment])\n",
        "            \n",
        "            token_row['y'] = row['label']\n",
        "            tokenized = tokenized.append(token_row, ignore_index=True)\n",
        "        return tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fYf8Of03Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(TOKENIZER_CLASS, PRETRAINED, True)\n",
        "test_tokens = tokenizer.tokenize_data(test_data)\n",
        "train_tokens = tokenizer.tokenize_data(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbQj_-rF9TKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(test_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZUOn4atS6ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens.to_csv('/content/drive/My Drive/Colab/data_qqp/test_tok.csv')\n",
        "train_tokens.to_csv('/content/drive/My Drive/Colab/data_qqp/train_tok.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpNONuQgVot2",
        "colab_type": "text"
      },
      "source": [
        "# **Load Data**\n",
        "- TBD: Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7C-VZeVoH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens = pd.read_csv('/content/drive/My Drive/Colab/data_qqp/test_tok.csv')\n",
        "test_tokens['i'] = test_tokens['i'].apply(lambda x: ast.literal_eval(x))\n",
        "test_tokens['s'] = test_tokens['s'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "train_tokens = pd.read_csv('/content/drive/My Drive/Colab/data_qqp/train_tok.csv')\n",
        "train_tokens['i'] = train_tokens['i'].apply(lambda x: ast.literal_eval(x))\n",
        "train_tokens['s'] = train_tokens['s'].apply(lambda x: ast.literal_eval(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oujXdPUWwhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display(test_tokens['i'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa1IXRK-VFgu",
        "colab_type": "text"
      },
      "source": [
        "# **BERT Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HVPFZadownS",
        "colab_type": "text"
      },
      "source": [
        "## Model Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GlyEXp_0yE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model_Classifier:\n",
        "    # initalize model\n",
        "    def __init__(self, model_class, pretrained_weights, pretrained_path=None):\n",
        "        if pretrained_path is not None:\n",
        "            self.model = model_class.from_pretrained(pretrained_path).cuda()\n",
        "        else:\n",
        "            self.model = model_class.from_pretrained(pretrained_weights).cuda()\n",
        "\n",
        "        self.TRAINING_ITERATIONS = 100000\n",
        "        self.WARMUP = 1000\n",
        "        self.BATCH_SIZE = 128\n",
        "        self.REPORT_FREQUENCY = 100\n",
        "        self.CHKPT_FREQUENCY = 5000\n",
        "#         self.model.eval()\n",
        "        \n",
        "    # train classifier\n",
        "    def train(self, data):\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "            {\"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.WARMUP, num_training_steps=self.TRAINING_ITERATIONS)\n",
        "        self.model.train()\n",
        "        bar = tqdm.tqdm(total=self.REPORT_FREQUENCY)\n",
        "        for i in range(1, self.TRAINING_ITERATIONS+1):\n",
        "            train_data = data.sample(n=self.BATCH_SIZE)\n",
        "            train_ids = torch.tensor(train_data['i'].values.tolist()).cuda()\n",
        "            train_segments = torch.tensor(train_data['s'].values.tolist()).cuda()\n",
        "            train_labels = torch.tensor(train_data['y'].values.tolist()).cuda()\n",
        "\n",
        "            # Uncomment this for BERT\n",
        "            # outputs = self.model(input_ids = train_ids, token_type_ids = train_segments, labels = train_labels)\n",
        "\n",
        "            # Comment this for DistilBERT\n",
        "            outputs = self.model(input_ids = train_ids, labels = train_labels)\n",
        "            loss = outputs[0].cuda()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            self.model.zero_grad()\n",
        "            bar.update(1)\n",
        "            if i % self.REPORT_FREQUENCY == 0:\n",
        "                bar.close()\n",
        "                print(\"%d: Loss - %s\" %(i, loss))\n",
        "                bar = tqdm.tqdm(total=self.REPORT_FREQUENCY)\n",
        "            if i % self.CHKPT_FREQUENCY == 0:\n",
        "                print(\"Saved %d\" %(i))\n",
        "                self.save(directory='CHKPT_' + str(int(i/self.CHKPT_FREQUENCY)))\n",
        "        bar.close()\n",
        "        return\n",
        "\n",
        "    # save model\n",
        "    def save(self, directory=None):\n",
        "      if directory is not None:\n",
        "          path = '/content/drive/My Drive/Colab/' + directory + '/'\n",
        "          if not os.path.exists(path):\n",
        "              os.makedirs(path)\n",
        "          print(\"HERE\")\n",
        "          self.model.save_pretrained('/content/drive/My Drive/Colab/' + directory + '/')\n",
        "      else:\n",
        "          self.model.save_pretrained('/content/drive/My Drive/Colab/model/')\n",
        "    \n",
        "    # predict values\n",
        "    def test(self, data):\n",
        "        self.model.eval()\n",
        "        ids = data['i'].values\n",
        "        segments = data['s'].values\n",
        "        labels = data['y'].values\n",
        "        correct = 0\n",
        "        total = len(labels)\n",
        "        for i in range(len(ids)):\n",
        "            outputs = self.model(input_ids = torch.tensor([ids[i]]).cuda())\n",
        "            probs = outputs[0][0]\n",
        "            softmax = torch.nn.functional.softmax(probs)\n",
        "            prediction = softmax.max(0)[1]\n",
        "            # print(\"pred: %f, act: %f @ %s\" %(prediction, labels[i], softmax[0]))\n",
        "            if prediction == labels[i]:\n",
        "                correct += 1\n",
        "        return correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzVMYXlpk49W",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKgl5Ks904oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_class = Model_Classifier(MODEL_CLASS, PRETRAINED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQGE_PiiaSOK",
        "colab_type": "code",
        "outputId": "d9d9beaf-71de-4d7c-d3c3-e7dcd82a7283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bert_class.train(train_tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100: Loss - tensor(0.6683, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200: Loss - tensor(0.6183, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300: Loss - tensor(0.5810, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "400: Loss - tensor(0.5980, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500: Loss - tensor(0.6048, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600: Loss - tensor(0.4941, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "700: Loss - tensor(0.5267, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "800: Loss - tensor(0.4692, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "900: Loss - tensor(0.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000: Loss - tensor(0.2828, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1100: Loss - tensor(0.2774, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1200: Loss - tensor(0.2170, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1300: Loss - tensor(0.3208, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400: Loss - tensor(0.2305, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1500: Loss - tensor(0.2662, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1600: Loss - tensor(0.1031, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1700: Loss - tensor(0.1782, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1800: Loss - tensor(0.1370, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1900: Loss - tensor(0.0584, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000: Loss - tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2100: Loss - tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2200: Loss - tensor(0.0679, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2300: Loss - tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400: Loss - tensor(0.0525, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2500: Loss - tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2600: Loss - tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2700: Loss - tensor(0.0504, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2800: Loss - tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2900: Loss - tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3000: Loss - tensor(0.0647, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3100: Loss - tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3200: Loss - tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3300: Loss - tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3400: Loss - tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3500: Loss - tensor(0.0396, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3600: Loss - tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3700: Loss - tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3800: Loss - tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3900: Loss - tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4000: Loss - tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4100: Loss - tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4200: Loss - tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4300: Loss - tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4400: Loss - tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4500: Loss - tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4600: Loss - tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4700: Loss - tensor(0.0241, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4800: Loss - tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4900: Loss - tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5000: Loss - tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "Saved 5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1a72e198b9dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-a306e85be1b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHKPT_FREQUENCY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CHKPT_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHKPT_FREQUENCY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a306e85be1b4>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab/model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36msave_pretrained\u001b[0;34m(self, save_directory)\u001b[0m\n\u001b[1;32m    282\u001b[0m         assert os.path.isdir(\n\u001b[1;32m    283\u001b[0m             \u001b[0msave_directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         ), \"Saving path should be a directory where the model and configuration can be saved\"\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Only save the model itself if we are using distributed training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Saving path should be a directory where the model and configuration can be saved"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_vFuEXZUKh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c530d64-a8cb-4367-9ae4-10be8ae76476"
      },
      "source": [
        "bert_class.save()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HERE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjiojR2kky7F",
        "colab_type": "text"
      },
      "source": [
        "## Test Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWBhT7C6k3Hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "05f347de-4428-469d-906a-17046c202331"
      },
      "source": [
        "bert_class = Model_Classifier(MODEL_CLASS, PRETRAINED, pretrained_path='/content/drive/My Drive/Colab/model/')\n",
        "acc = bert_class.test(test_tokens)\n",
        "print(acc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7666174298375185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdbvnMYHVhho",
        "colab_type": "text"
      },
      "source": [
        "# **Custom Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h355NpHZ0zv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model:\n",
        "    # initalize model\n",
        "    def __init__(self, model_class, tokenizer_class, pretrained_weights):\n",
        "        self.model = model_class.from_pretrained(pretrained_weights)\n",
        "        \n",
        "    # Generate embeddings\n",
        "    def get_embeddings(self, data):\n",
        "        return\n",
        "        \n",
        "    # \n",
        "    def train(self, data):\n",
        "        return\n",
        "    \n",
        "    # \n",
        "    def test(self, data):\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}